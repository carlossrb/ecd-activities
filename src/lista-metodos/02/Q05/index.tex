
\noindent \textcolor{COLOR1}{Questão 05)} Dado $n$ um número natural maior ou igual a 2, considere a matriz $A$ de tamanho
$n \times n$ cuja entrada na posição $i, j$ é $max{i, j}$. Na seguinte função foi implementado o método
de Gauss-Jordan para resolver sistemas lineares cuja matriz dos coeficientes é uma matriz $A$ da
forma anterior e os termos independentes são matrizes colunas com entradas inteiras quaisquer.
\\

\begin{lstlisting}
    import numpy as np


    def GaussJordan(A, b):
        b = np.array(b, dtype=float)
        A = np.array(A, dtype=float)
        Ab = np.column_stack((A, b))
        n = np.shape(Ab)[0]
        m = np.shape(Ab)[1]
        for i in range(0, n - 1, 1):
            if Ab[i, i] == 0:
                print("Divisao por zero")
                break
            for k in range(i + 1, n, 1):
                fator = Ab[k, i] / Ab[i, i]
                Ab[k, :] = Ab[k, :] - Ab[i, :] * fator
        for i in range(n - 1, -1, -1):
            for k in range(i - 1, -1, -1):
                fator = Ab[k, i] / Ab[i, i]
                Ab[k, :] = Ab[k, :] - Ab[i, :] * fator
            Ab[i, :] = Ab[i, :] / Ab[i, i]
        x = np.copy(Ab[:, m - 1])
        return x
\end{lstlisting}


Usando Python defina matrizes da forma acima e matrizes colunas $b$ com entradas inteiras aleatórias de tamanhos 5, 10, 15, 50, 100, 500, 1000 (especifique os comandos utilizados). Use as seguintes linhas para comparar o tempo de execução da função Gauss-Jordan (acima) e da função do numpy (linalg.solve) ao resolver cada sistema linear $AX = b$ definido anteriormente
\\

\begin{lstlisting}
    inicio = time.time()
    xgauss = GaussJordan(A,b)
    fim = time.time()
    print("Tempo de Gauss-Jordan:",fim - inicio)
    inicio = time.time()
    xnump = np.linalg.solve(A,b)
    fim = time.time()
    print("Tempo de numpy-solve:",fim - inicio)    
\end{lstlisting}

Qual a conclusão que você pode tirar deste experimento?
\\

Inicialmente, comparando os tempos de execução para a questão anterior, percebeu-se que o tempo de execução do numpy é menor que o de Gauss-Jordan, porém, há uma oscilação: vezes a diferença é bastante superior, por outras não muito. No geral, o método do numpy apresenta uma tendencia de sempre permanecer com tempos menores na execução. Isso possivelmente se deve a algoritmos otimizados para resolução interna do sistema, que apresentam um big O mais rápido.
\\

Para testes em matrizes de tamanho $2 \times 2$ até $1000 \times 1000$ elaborou-se um gráfico de tempos de execução com o seguinte algoritmo e percebeu-se que o tempo de execução do numpy continua sendo menor que o de Gauss-Jordan.\\


\begin{lstlisting}
import numpy as np
import time as time
import matplotlib.pyplot as plt

initial = 2
final = 1000
times_gauss = []
times_numpy = []
for i in range(initial, final):
    A = np.random.randint(-5, 5, size=(i, i))
    b = np.random.randint(-5, 5, size=(i))
    if np.linalg.det(A) != 0:
        inicio = time.time()
        xgauss = GaussJordan(A, b)
        fim = time.time()
        times_gauss.append((fim-inicio)*1000) #tempo em s
        inicio = time.time()
        xnump = np.linalg.solve(A, b)
        fim = time.time()  
        times_numpy.append((fim-inicio)*1000) #tempo em s

plt.title("Tempo de execucao")
plt.xlabel("Passo")
plt.ylabel("Tempo (s)")

df={'x_values': np.arange(initial, final), 'y1_values': times_gauss, 
'y2_values': times_numpy }
 
plt.plot( 'x_values', 'y1_values', data=df, marker='', color='olive',
linewidth=2, label="gauss")
plt.plot( 'x_values', 'y2_values', data=df, marker='', color='blue', 
linewidth=2, linestyle='dashed', label="numpy")
# show legend
plt.legend()

plt.show()h
\end{lstlisting}