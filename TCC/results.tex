\section{Resultados}
\label{sec:results}

Após a limpeza dos dados, iniciou-se o processo de análise dos mesmos. Com isso, algumas considerações poderam ser tomadas. Como dito \textit{a priori}, por ser tão abrangente, essa análise foi limitada ao sistema de avaliação feito pelos clientes após a confirmação de entrega do produto. Assim, o consumidor pode dar nota de 1 a 5 para o produto, sendo 1 o mais baixo e 5 o mais alto.


\begin{figure}[H]
    \centering
    \includegraphics[trim={0cm 2cm 3cm 2cm},clip,scale=0.65]{./figs/eval.png}
    \caption{Distribuição das avaliações}
    \label{fig:evalDistribution}
\end{figure}

À primeira vista com o quantitativo de notas, é possível perceber que essa  distribuição é dada em forma de ``J" e é bastante típica em E-commerces. Grande  quantidade de avaliações 5, 4 e 1, pequena quantidade de 2 e 3.

Este tipo de distribuição pode ocorrer por várias razões. Uma possível explicação é que os clientes que estão extremamente satisfeitos ou insatisfeitos com um produto são mais propensos a deixar uma avaliação do que aqueles que têm uma experiência neutra. Isso pode resultar em uma concentração maior de avaliações com classificações muito altas ou muito baixas.

Outra possível explicação é que os clientes que têm uma experiência neutra com um produto podem não se sentir motivados a deixar uma avaliação. Eles podem sentir que o produto foi bom, mas não excepcional, e, portanto, não vale a pena dedicar tempo para escrever uma avaliação. Isso pode levar a um menor número de avaliações com classificações médias.

A distribuição em forma de ``J" das avaliações pode ser importante para as empresas entenderem, pois pode fornecer informações sobre a satisfação do cliente e a qualidade do produto. Se um produto tiver uma alta concentração de avaliações muito positivas, pode ser um indicador de forte satisfação do cliente e um produto de alta qualidade. No entanto, também é importante considerar o número de avaliações e a média geral das classificações, já que um pequeno número de avaliações pode distorcer a distribuição.

Seguidamente, plotou-se a distribuição binária das avaliações conforme foi seccionado na etapa de tratamento dos dados. De forma coerente com a \autoref{fig:evalDistribution} e com a divisão adotada, a maior parte das avaliações são positivas.

\begin{figure}[H]
    \centering
    \includegraphics[trim={0cm 2cm 3cm 2cm},clip,scale=0.6]{./figs/bin_eval.png}
    \caption{Distribuição das avaliações binárias}
    \label{fig:binEvalDistribution}
\end{figure}

Uma nuvem de palavras então é gerada a partir de um conjunto de dados de texto referente aos comentários avaliativos dos clientes. As palavras são extraídas do texto e organizadas em uma nuvem, em que as palavras mais frequentes são maiores e as menos frequentes são menores. A nuvem de palavras pode ser usada para ajudar a identificar tópicos e padrões importantes em um conjunto de dados de texto e para comunicar visualmente essas informações.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.8]{./figs/word_cloud.png}
    \caption{Nuvem de palavras destacando os principais termos utilizados}
    \label{fig:wordCloud}
\end{figure}

Essa técnica visual pode ser usada em vários campos, incluindo análise de sentimentos, mineração de opiniões, análise de redes sociais, pesquisa de mercado e análise de feedback de clientes como o caso em específico. Além disso, por ser uma forma visualmente atraente de resumir informações e destacar pontos importantes, é bastante útil para relatórios e análises.

Tendo feito a tokenização das palavras, transformando-as em listas de numeros, filtrado pelas \textit{stopwords} e feito um processo de padronização textual, separou-se o dataset entre treino e teste e prosseguiu para as demais análises com os algorítmos de aprendizado de máquina e redes neurais.

Dentre os algoritmos de machine learning, encontrou-se as seguintes acurácias:

\begin{table}[H]
    \centering
    \begin{tabular}{l|cccc}
        \hline
        { modelo}      & { Reg. Logística} & { F. Aleatórias} & { XGBoost} & { Naive Bayes} \\ \hline\hline
        { treino (\%)} & { 73.9}           & { 99.6}          & { 93.5}    & { 74.0}        \\\hline
        { teste (\%)}  & { 73.3}           & { 78.2}          & { 82.1}    & { 74.0}
    \end{tabular}
\end{table}

Observa-se que nos modelos de Florestas Aleatórias e XGBoost apresentou-se discrepâncias significativas entre as suas respectivas acurácias de treino e de teste. Essa diferença entre a acurácia (ou outra métrica de desempenho) é conhecida como a discrepância de generalização. Isso pode ter acontecido por diferentes motivos:

\begin{itemize}
    \item Overfitting: O modelo pode memorizar o conjunto de treinamento em vez de aprender os padrões subjacentes dos dados. Isso pode resultar em uma acurácia alta no conjunto de treinamento, mas uma acurácia baixa no conjunto de teste. Para evitar o overfitting, é importante usar técnicas como a regularização, a seleção de características e o aumento de dados.
    \item Diferenças entre os dados de treinamento e teste: Os dados de treinamento podem ser diferentes dos dados de teste, o que pode levar a discrepâncias na acurácia. Por exemplo, os dados de treinamento podem ter menos variabilidade do que os dados de teste, ou podem conter exemplos raros que não estão presentes no conjunto de teste.
    \item Tamanho do conjunto de dados: Quando o conjunto de dados é pequeno, é possível que a variação estatística nos resultados seja grande, levando a diferenças na acurácia entre o treinamento e teste.
\end{itemize}

É importante entender que uma discrepância de generalização não é necessariamente ruim, pois é possível que o modelo esteja apenas se adaptando aos dados de treinamento de forma mais eficaz. No entanto, se a discrepância for muito grande, pode ser um sinal de que o modelo precisa de ajustes. O objetivo é ter um modelo que generalize bem para novos dados e não apenas memorize os dados de treinamento.


% Além disso, os comentários avaliativos também foram considerados, sendo essas mensagens tokenizadas em listas de números e as avaliações numéricas [1,5] foram transformadas em variáveis categóricas binárias, sendo o valor de 1 atribuido para uma avaliação positiva variando de [3,5] e 0 para uma avaliação negativa variando de [1,2]. Com base nesses dois valores de entrada, analisou-se 4 modelos de aprendizado de máquina clássicos e comparou-lhes com uma rede neural recorrente (LSTM)