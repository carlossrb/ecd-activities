\subsection{Redes Neurais}

\input{tikz/neuralNetwork.tikz.tex}

Redes Neurais Artificiais (RNAs) são modelos computacionais que se inspiram no funcionamento do cérebro humano e têm sido amplamente utilizadas para tarefas de classificação, previsão e reconhecimento de padrões em diferentes áreas do conhecimento. O conceito de RNA foi proposto por \cite{mcculloch1943logical}, mas foi apenas a partir da década de 1980, com o desenvolvimento de técnicas de treinamento de redes profundas, que as RNAs se tornaram uma ferramenta poderosa para análise de dados \cite{lecun2015deep}.

Uma RNA é composta por camadas de neurônios artificiais, cada um com uma função de ativação que transforma a entrada recebida em uma saída. A primeira camada é a camada de entrada, que recebe os dados a serem processados. A última camada é a camada de saída, que produz a resposta final da RNA. Entre as camadas de entrada e saída, podem ser adicionadas várias camadas ocultas, que ajudam a extrair características dos dados de entrada.

O processo de treinamento de uma RNA consiste em ajustar os pesos sinápticos entre os neurônios para que a rede produza a saída correta para cada entrada. O algoritmo mais comum de treinamento é o Backpropagation, proposto por \cite{rumelhart1986parallel}. O Backpropagation utiliza o método do gradiente descendente para minimizar a função de custo da RNA em relação aos pesos sinápticos.

Uma das principais vantagens das RNAs é a capacidade de lidar com dados complexos e não lineares. Além disso, as RNAs podem ser utilizadas em problemas de classificação, previsão e reconhecimento de padrões em diferentes áreas, como visão computacional, processamento de fala, processamento de texto e bioinformática.

No entanto, elas possuem algumas desvantagens, como a dificuldade de interpretação dos resultados e o risco de overfitting, que ocorre quando a rede se ajusta demais aos dados de treinamento e não consegue generalizar para novos dados.

As redes neurais artificiais são compostas por uma série de camadas de neurônios, que realizam operações matemáticas nas entradas recebidas para gerar saídas. A formulação matemática dessas operações pode variar de acordo com a arquitetura da rede, mas em geral envolvem uma combinação linear das entradas, seguida de uma função não linear de ativação.

Abaixo tem-se as equações matemáticas para uma rede neural \textit{feedforward} de três camadas, com $n^{(l)}$ neurônios na camada $l$:

\begin{equation}
    \begin{aligned}
         & z_j^{(2)} = \sum\limits_{i=1}^{n^{(1)}} w_{ij}^{(1)} x_i + b_j^{(1)}       \\
         & h_j^{(2)} = f(z_j^{(2)})                                                   \\
         & z_k^{(3)} = \sum\limits_{j=1}^{n^{(2)}} w_{jk}^{(2)} h_j^{(2)} + b_k^{(2)} \\
         & y_k = f(z_k^{(3)})
    \end{aligned}
\end{equation}

Na equação acima, $x_i$ representa a entrada na posição $i$, $w_{ij}^{(1)}$ representa o peso associado à conexão entre o neurônio $i$ da camada de entrada e o neurônio $j$ da camada oculta, $b_j^{(1)}$ é o viés associado ao neurônio $j$ da camada oculta, $f$ é a função de ativação, $h_j^{(2)}$ é a saída do neurônio $j$ da camada oculta, $w_{jk}^{(2)}$ é o peso associado à conexão entre o neurônio $j$ da camada oculta e o neurônio $k$ da camada de saída, $b_k^{(2)}$ é o viés associado ao neurônio $k$ da camada de saída e $y_k$ é a saída final da rede neural.

É importante notar que a escolha da função de ativação pode influenciar significativamente o comportamento da rede neural, permitindo, por exemplo, que ela aprenda a modelar funções não-lineares complexas. Algumas funções de ativação comuns incluem a função sigmoide, a função tangente hiperbólica e a função ReLU (Rectified Linear Unit).

\subsubsection{Redes Neurais Artificiais LSTM }

\input{tikz/lstm.tikz.tex}

Uma rede neural artificial \textit{Long Short-Term Memory} (LSTM) é um tipo especializado de rede neural recorrente (RNN) projetada para lidar com o problema de dependência a longo prazo em sequências de dados. Foi proposta por \cite{hochreiter1997long} como uma solução para o problema de desvanecimento do gradiente em RNNs tradicionais.

O problema de desvanecimento do gradiente ocorre quando o gradiente calculado durante o processo de retropropagação se torna muito pequeno à medida que se propaga pelas camadas da rede, o que dificulta o aprendizado de dependências a longo prazo. Isso limita a capacidade das RNNs tradicionais em lidar com sequências de dados que envolvem dependências a longo prazo, como em análise de séries temporais ou processamento de linguagem natural.

A principal característica da LSTM é a presença de unidades de memória, que são capazes de lembrar informações relevantes por um período prolongado de tempo. Essas unidades são compostas por três portões principais: o portão de entrada, o portão de esquecimento e o portão de saída. O portão de entrada controla a quantidade de informação que é adicionada à unidade de memória, enquanto o portão de esquecimento controla a quantidade de informação que é descartada. O portão de saída controla a quantidade de informação que é enviada para a próxima unidade da rede.

Durante o treinamento, a LSTM é capaz de aprender a modificar seus portões de entrada, esquecimento e saída, a fim de manter as informações relevantes na memória e descartar as informações irrelevantes. Os pesos das conexões entre as unidades de memória são atualizados usando o algoritmo de retropropagação através do tempo (BPTT).

A arquitetura LSTM foi amplamente utilizada em diversas aplicações, incluindo processamento de linguagem natural, reconhecimento de fala e análise de séries temporais. Por exemplo, \cite{graves2013speech} utilizaram LSTMs para melhorar o reconhecimento de fala em 2013. Além disso, \cite{gers1999learning} propuseram uma abordagem de aprendizado contínuo com LSTMs, chamada de "learning to forget", que permite que a rede esqueça informações irrelevantes à medida que recebe novos dados.

Para o trabalho específico usou-se o \textit{tensorflow keras} com os seguintes valores:

\begin{itemize}
    \item unidades de células: 32
    \item camadas: 2
    \item épocas: 20
    \item taxa de aprendizagem: 0.01
    \item neurônios: 32
\end{itemize}

Abaixo estão algumas formulações matemáticas para uma unidade LSTM:

\begin{equation}
    \begin{aligned}
        i_t        & = \sigma(W_i x_t + U_i h_{t-1} + b_i)      \\
        f_t        & = \sigma(W_f x_t + U_f h_{t-1} + b_f)      \\
        \tilde{c}t & = \text{tanh}(W_c x_t + U_c h{t-1} + b_c)  \\
        c_t        & = f_t \odot c_{t-1} + i_t \odot \tilde{c}t \\
        o_t        & = \sigma(W_o x_t + U_o h{t-1} + b_o)       \\
        h_t        & = o_t \odot \text{tanh}(c_t)
    \end{aligned}
\end{equation}

Nessa formulação, $x_t$ é a entrada na unidade LSTM no tempo $t$, $h_{t-1}$ é o estado oculto da unidade LSTM no tempo $t-1$, $i_t$, $f_t$, $\tilde{c}_t$, $c_t$, $o_t$ e $h_t$ são as portas de entrada, esquecimento, memória, saída e o estado oculto da unidade LSTM no tempo $t$, respectivamente. $\sigma$ é a função de ativação sigmóide, $\text{tanh}$ é a função tangente hiperbólica, $\odot$ denota a multiplicação elementar ponto-a-ponto (também conhecida como produto Hadamard) e $W$ e $U$ são matrizes de pesos que são aprendidas durante o treinamento, enquanto $b$ é o vetor de bias.

Essa formulação é apenas um exemplo, já que existem várias variações da arquitetura LSTM, mas ela ilustra a ideia geral da arquitetura. A unidade LSTM é composta por portas que controlam a quantidade de informação que é adicionada, esquecida ou transmitida para a próxima unidade da rede. Além disso, a unidade LSTM mantém uma memória interna que pode ser atualizada ou esquecida ao longo do tempo.