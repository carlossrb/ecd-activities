\section{Conclusões}
\label{sec:conclu}

Com base na análise dos resultados, podemos concluir que a rede neural artificial LSTM apresentou a melhor performance em relação aos outros algoritmos de \textit{machine learning} avaliados. A acurácia da LSTM foi de $90\%$, o que indica que o modelo foi capaz de classificar corretamente a grande maioria dos dados.

Se tratando de \textit{tradeoff}, na prática, muitas vezes é necessário encontrar um equilíbrio entre a rapidez da resposta e a precisão do modelo. Isso ocorre porque muitas aplicações em tempo real exigem que a resposta seja obtida em um curto espaço de tempo, enquanto outras aplicações, como pesquisa médica ou financeira, priorizam a precisão.

A escolha do modelo ideal depende de vários fatores, como o tamanho dos dados, a complexidade do problema e a disponibilidade de recursos de computação. Modelos mais complexos, como as redes neurais, podem ter uma acurácia muito alta, mas exigem uma grande quantidade de tempo de processamento, enquanto modelos mais simples, como regressão logística ou Naive Bayes, têm tempos de processamento menores, mas podem ter uma acurácia menor.

As Florestas Aleatórias e o XGBoost são modelos intermediários em termos de complexidade e tempo de execução. Já o LightGBM possui um baixo tempo de execução no geral. Esses modelos podem ser mais adequados para muitas aplicações, pois têm uma acurácia razoável e são ágeis o suficiente para muitas tarefas em tempo real.

Outrossim, é necessário destacar que o XGBoost e LightGBM possuem algumas vantagens em relação a redes neurais como a LSTM.

Uma das delas é a sua capacidade de lidar com dados heterogêneos e faltantes de forma eficiente, o que pode ser um desafio para redes neurais. Além disso, com a visão de um negócio, onde a velocidade é importante, o LightGBM e XGBoost são modelos mais simples e rápidos de treinar do que redes neurais, o que pode ser uma vantagem em cenários em que o tempo e recursos computacionais são limitados.

O XGBoost também apresenta interpretabilidade, uma vez que ele permite identificar as variáveis mais importantes para a classificação dos dados. As redes neurais, embora apresentem alta performance em muitas tarefas, são frequentemente consideradas caixas pretas, dificultando a interpretação dos resultados.

Já o LightGBM é consideravelmente mais rápido do que o XGBoost, pois usa uma técnica de otimização chamada de "histogram-based" para encontrar os melhores pontos de divisão de árvore. Isso permite que ele processe conjuntos de dados maiores e mais complexos em menos tempo.

Outras vantagens envolvendo os dois melhores modelos de aprendizado de máquina envolvem: 1 - O LightGBM usar menos memória do que o XGBoost, pois utiliza uma técnica de amostragem chamada "leaf-wise" em vez de "level-wise". Isso permite que ele crie árvores mais profundas com menos nós. 2 - O LightGBM ter melhor desempenho em conjuntos de dados esparsos ao ser melhor em lidar com conjuntos de dados esparsos, pois utiliza uma técnica de exclusão de zeros para reduzir a sobrecarga computacional em recursos esparsos

Portanto, embora a LSTM tenha apresentado a melhor performance na análise classificatória realizada, o LightGBM e XGBoost podem ser boas opções em cenários em que a interpretabilidade e o processamento de dados faltantes são prioridades.

Por outro lado, a LSTM consegue lidar com dados sequenciais e com dependências de longo prazo, o que pode ser um desafio para algoritmos de aprendizado de máquina tradicionais. Isso torna a LSTM uma escolha popular para tarefas de processamento de linguagem natural, reconhecimento de fala, análise de séries temporais, entre outras aplicações em que o histórico de dados é importante. Além disso, ela é capaz de aprender padrões complexos em dados sequenciais sem a necessidade de engenharia manual de características, o que pode ser um processo demorado e sujeito a erros nos outros algoritmos, incluindo o XGBoost. Isso pode resultar em um desempenho melhor para a LSTM em tarefas em que há uma grande quantidade de dados sequenciais.

Outra vantagem da LSTM é a sua capacidade de lidar com dados de entrada de diferentes tipos e tamanhos, como sequências de palavras, imagens e dados numéricos. Isso torna a LSTM uma escolha popular em aplicações em que os dados podem ter diferentes formatos, como reconhecimento de fala e tradução automática.

Para análise de sentimentos em reviews de usuários, a LSTM pode ser mais vantajosa do que o LightGBM e XGBoost. Isso ocorre porque as análises de sentimentos geralmente envolvem dados sequenciais, como sequências de palavras ou frases em uma revisão, e as LSTMs são projetadas especificamente para trabalhar com dados sequenciais e são capazes de aprender padrões em sequências de dados de maneira mais eficiente do que algoritmos de aprendizado de máquina.

Além disso, as LSTMs têm a capacidade de capturar dependências de longo prazo nos dados sequenciais, o que pode ser importante para a análise de sentimentos em reviews de usuários, já que as opiniões dos usuários muitas vezes são expressas em frases e parágrafos complexos e detalhados. Isso possivelmente pode ser percebido como o único modelo que mostrou maior quantidade de resultados de avaliações negativas corretamente, conforme a sua matriz de confusão. Os demais modelos tiveram dificuldade em classificar corretamente as avaliações negativas dos consumidores.

No entanto, é importante ressaltar que a escolha do algoritmo de \textit{machine learning} depende do conjunto de dados e do problema em questão. Algoritmos mais simples podem ser mais eficazes em alguns cenários, enquanto algoritmos mais complexos, como redes neurais, podem ser necessários para lidar com dados mais complexos e variáveis. Em última análise, a escolha do algoritmo deve ser baseada em uma análise cuidadosa dos dados e das necessidades específicas do problema em questão.

Como sugestão para trabalhos fututos pode-se citar os seguintes:

\begin{itemize}
    \item Investigação da aplicabilidade dos modelos avaliados em diferentes conjuntos de dados e tipos de problema, para avaliar se os resultados obtidos se mantêm consistentes em diferentes cenários.
    \item Avaliação de outras métricas de desempenho além da acurácia e área sob a curva ROC, como F1-score, precisão e recall, para avaliar melhor o desempenho dos modelos em diferentes situações.
    \item Investigação de técnicas de interpretabilidade em redes neurais, como SHAP e LIME, para tornar os resultados desses modelos mais compreensíveis e confiáveis em aplicações práticas.
    \item Exploração de técnicas de otimização de tempo de execução para redes neurais, como a utilização de GPUs ou técnicas de redução de dimensionalidade, para tornar esses modelos mais práticos para aplicações em tempo real.
    \item Comparação de diferentes versões dos modelos avaliados, como o uso de árvores de decisão em vez de florestas aleatórias, para avaliar se algumas variações são mais adequadas para determinados tipos de dados ou problemas.
\end{itemize}