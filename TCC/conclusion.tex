\section{Conclusões}
\label{sec:conclu}

Com base na análise dos resultados, podemos concluir que a rede neural artificial LSTM apresentou a melhor performance em relação aos outros algoritmos de \textit{machine learning} avaliados. A acurácia da LSTM foi de $90\%$, o que indica que o modelo foi capaz de classificar corretamente a grande maioria dos dados.

Ao avaliar a curva ROC, podemos observar que a LSTM também apresentou a maior área sob a curva, indicando uma maior capacidade de distinguir entre as classes. Esse resultado é consistente com a análise das matrizes de confusão, que mostraram que a LSTM teve o melhor desempenho na classificação correta das amostras.

O XGBoost e LightGBM também apresentaram resultados promissores, tendo o XGBoost uma acurácia um pouco melhor de $82\%$ e uma área sob a curva ROC de 0,89. No entanto, as matrizes de confusão indicaram que os modelos cometeram mais erros do que a LSTM na classificação de algumas amostras.

Por outro lado, a regressão logística e o Naive Bayes apresentaram as piores performances, com acurácias de $73\%$ e $74\%$, respectivamente, e áreas sob a curva ROC menores do que os outros modelos avaliados.

Se tratando de \textit{tradeoff}, na prática, muitas vezes é necessário encontrar um equilíbrio entre a rapidez da resposta e a precisão do modelo. Isso ocorre porque muitas aplicações em tempo real exigem que a resposta seja obtida em um curto espaço de tempo, enquanto outras aplicações, como pesquisa médica ou financeira, priorizam a precisão.

A escolha do modelo ideal depende de vários fatores, como o tamanho dos dados, a complexidade do problema e a disponibilidade de recursos de computação. Modelos mais complexos, como as redes neurais, podem ter uma acurácia muito alta, mas exigem uma grande quantidade de tempo de processamento, enquanto modelos mais simples, como regressão logística ou Naive Bayes, têm tempos de processamento menores, mas podem ter uma acurácia menor.

As Florestas Aleatórias e o XGBoost são modelos intermediários em termos de complexidade e tempo de execução. Já o LightGBM possui um baixo tempo de execução no geral. Esses modelos podem ser mais adequados para muitas aplicações, pois têm uma acurácia razoável e são ágeis o suficiente para muitas tarefas em tempo real.

No caso específico apresentado no trabalho, a regressão logística tem um tempo de execução muito maior do que os outros modelos, o que pode ser um fator limitante em muitas aplicações. Por outro lado, o Naive Bayes tem um tempo de execução muito curto, mas também tem a menor acurácia entre os modelos apresentados.

A rede neural LSTM tem uma acurácia muito alta, mas um tempo de execução extremamente longo, o que pode torná-la impraticável para muitas aplicações em tempo real. No entanto, para aplicações onde a precisão é o fator mais importante, como diagnóstico médico ou detecção de fraudes financeiras, esse modelo pode ser a melhor opção.

Outrossim, é necessário destacar que o XGBoost e LightGBM possuem algumas vantagens em relação a redes neurais como a LSTM.

Uma das delas é a sua capacidade de lidar com dados heterogêneos e faltantes de forma eficiente, o que pode ser um desafio para redes neurais. Além disso, com a visão de um negócio, onde a velocidade é importante, o LightGBM e XGBoost são modelos mais simples e rápidos de treinar do que redes neurais, o que pode ser uma vantagem em cenários em que o tempo e recursos computacionais são limitados.

O XGBoost também apresenta interpretabilidade, uma vez que ele permite identificar as variáveis mais importantes para a classificação dos dados. As redes neurais, embora apresentem alta performance em muitas tarefas, são frequentemente consideradas caixas pretas, dificultando a interpretação dos resultados.

Já o LightGBM é consideravelmente mais rápido do que o XGBoost, pois usa uma técnica de otimização chamada de "histogram-based" para encontrar os melhores pontos de divisão de árvore. Isso permite que ele processe conjuntos de dados maiores e mais complexos em menos tempo.

Outras vantagens envolvendo os dois melhores modelos de aprendizado de máquina envolvem: 1 - O LightGBM usar menos memória do que o XGBoost, pois utiliza uma técnica de amostragem chamada "leaf-wise" em vez de "level-wise". Isso permite que ele crie árvores mais profundas com menos nós. 2 - O LightGBM ter melhor desempenho em conjuntos de dados esparsos ao ser melhor em lidar com conjuntos de dados esparsos, pois utiliza uma técnica de exclusão de zeros para reduzir a sobrecarga computacional em recursos esparsos

Portanto, embora a LSTM tenha apresentado a melhor performance na análise classificatória realizada, o LightGBM e XGBoost podem ser boas opções em cenários em que a interpretabilidade e o processamento de dados faltantes são prioridades.

Por outro lado, a LSTM consegue lidar com dados sequenciais e com dependências de longo prazo, o que pode ser um desafio para algoritmos de aprendizado de máquina tradicionais. Isso torna a LSTM uma escolha popular para tarefas de processamento de linguagem natural, reconhecimento de fala, análise de séries temporais, entre outras aplicações em que o histórico de dados é importante. Além disso, ela é capaz de aprender padrões complexos em dados sequenciais sem a necessidade de engenharia manual de características, o que pode ser um processo demorado e sujeito a erros nos outros algoritmos, incluindo o XGBoost. Isso pode resultar em um desempenho melhor para a LSTM em tarefas em que há uma grande quantidade de dados sequenciais.

Outra vantagem da LSTM é a sua capacidade de lidar com dados de entrada de diferentes tipos e tamanhos, como sequências de palavras, imagens e dados numéricos. Isso torna a LSTM uma escolha popular em aplicações em que os dados podem ter diferentes formatos, como reconhecimento de fala e tradução automática.

Para análise de sentimentos em reviews de usuários, a LSTM pode ser mais vantajosa do que o LightGBM e XGBoost. Isso ocorre porque as análises de sentimentos geralmente envolvem dados sequenciais, como sequências de palavras ou frases em uma revisão, e as LSTMs são projetadas especificamente para trabalhar com dados sequenciais e são capazes de aprender padrões em sequências de dados de maneira mais eficiente do que algoritmos de aprendizado de máquina.

Além disso, as LSTMs têm a capacidade de capturar dependências de longo prazo nos dados sequenciais, o que pode ser importante para a análise de sentimentos em reviews de usuários, já que as opiniões dos usuários muitas vezes são expressas em frases e parágrafos complexos e detalhados. Isso possivelmente pode ser percebido como o único modelo que mostrou maior quantidade de resultados de avaliações negativas corretamente, conforme a sua matriz de confusão. Os demais modelos tiveram dificuldade em classificar corretamente as avaliações negativas dos consumidores.

No entanto, é importante ressaltar que a escolha do algoritmo de \textit{machine learning} depende do conjunto de dados e do problema em questão. Algoritmos mais simples podem ser mais eficazes em alguns cenários, enquanto algoritmos mais complexos, como redes neurais, podem ser necessários para lidar com dados mais complexos e variáveis. Em última análise, a escolha do algoritmo deve ser baseada em uma análise cuidadosa dos dados e das necessidades específicas do problema em questão.